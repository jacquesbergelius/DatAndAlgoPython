<!--- https://nvie.com/posts/iterators-vs-generators/ -->

# Iterable

Most containers (list, set, dictionary, tuple, string, ...) are also iterable. An _iterable_ is any object, not necessarily a data structure, that can return an iterator (with the purpose of returning all of its elements).
```text
>>> x = [1, 2, 3]
>>> y = iter(x)
>>> z = iter(x)
>>> next(y)
1
>>> next(y)
2
>>> next(z)
1
>>> type(x)
<class 'list'>
>>> type(y)
<class 'list_iterator'>
```
Here, `x` is the iterable, while `y` and `z` are two individual instances of an iterator, producing values from the iterable `x`. Both `y` and `z` hold state, as you can see from the example. In this example, `x` is a data structure (a list), but that is not a requirement.

# Iterator

In Python, an iterator is an object that represents a stream of data. It provides a way to access elements of a container (such as a list or a tuple) one at a time without needing to know the underlying structure of the container. Iterator is a stateful helper object that will produce the next value when you call `next()` on it. Any object that has a `__next__()` method is therefore an iterator. How it produces a value is irrelevant. We can think of an iterator as a value factory. Each time you ask it for "the next" value, it knows how to compute it because it holds internal state.

Iterators in Python must implement two methods:

1. `__iter__()`: This method returns the iterator object itself. It allows an iterator to be used where an iterable is expected, for example, in a for loop.

2. `__next__()`: This method returns the next item from the iterator. If there are no more items, it raises a `StopIteration` exception.

Here's a simple example of creating and using an iterator in Python:

```python
class MyIterator:
    def __init__(self, data):
        self.data = data
        self.index = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.index >= len(self.data):
            raise StopIteration
        result = self.data[self.index]
        self.index += 1
        return result
```
Using the iterator:
```text
my_list = [1, 2, 3, 4, 5]
my_iterator = MyIterator(my_list)

for item in my_iterator:
    print(item)
```

In this example, `MyIterator` is a custom iterator that iterates over a list. It implements the `__iter__()` and `__next__()` methods. When used in a for loop, it iterates over the elements of the list and prints each element.

Python provides built-in functions like `iter()` and `next()` which can be used to create and interact with iterators. `itertools` module provides a collection of tools for handling iterators, for example
```text
>>> from itertools import count
>>> counter = count(start=13)
>>> next(counter)
13
>>> next(counter)
14
```

It is possible to use the internal state of the iterator to generate Fibonacci numbers, like
```python
class fib:
    def __init__(self):
        self.prev = 0
        self.curr = 1

    def __iter__(self):
        return self

    def __next__(self):
        value = self.curr
        self.curr += self.prev
        self.prev = value
        return value
```

```text
>>> from itertools import islice
>>> f = fib()
>>> list(islice(f, 0, 10))
[1, 1, 2, 3, 5, 8, 13, 21, 34, 55]
```

The state inside this iterator is fully kept inside the prev and curr instance variables, and are used for subsequent calls to the iterator. Every call to `next()` does two important things:
- Modify its state for the next `next()` call;
- Produce the result for the current call.

We can think the iterator as a _lazy factory_ that is idle until you ask it for a value, which is when it starts to buzz and produce a single value, after which it turns idle again.

Iterators are widely used in Python, especially in constructs like for loops, list comprehensions, and generators. They provide a clean and efficient way to traverse sequences of data, especially when dealing with large datasets or when the entire dataset is not available upfront.

# Generator

A generator is a special type of iterator that generates values lazily, on-the-fly, rather than storing them in memory all at once. Generators are defined using functions and the `yield` statement.

Here's a simple example of a generator function:

```python
def my_generator():
    yield 1
    yield 2
    yield 3

# Using the generator
gen = my_generator()
print(next(gen))  # Output: 1
print(next(gen))  # Output: 2
print(next(gen))  # Output: 3
```

In this example, `my_generator()` is a generator function that yields values 1, 2, and 3 when called. The `next()` function is used to iterate over the generator, fetching one value at a time.

A generator allows you to write iterators much like the Fibonacci sequence iterator example above, but in an elegant succinct syntax that avoids writing classes with `__iter__()` and `__next__()` methods. Here is the same Fibonacci sequence factory, but written as a generator:
```python
def fib():
    prev, curr = 0, 1
    while True:
        yield curr
        prev, curr = curr, prev + curr
```
`fib` is defined as a normal Python function, nothing special. Notice, however, that there's no return keyword inside the function body. The return value of the function will be a generator (read: an iterator, a factory, a stateful helper object). Let's check what happens when we use it:
```text
>>> f = fib()
>>> list(islice(f, 0, 10))
[1, 1, 2, 3, 5, 8, 13, 21, 34, 55]
```
Now when `f = fib()` is called, the generator (the factory) is instantiated and returned. No code will be executed at this point: the generator starts in an idle state initially. To be explicit: the `line prev, curr = 0, 1` is not executed yet.

Then, this generator instance is wrapped in an `islice()`. This is itself also an iterator, so idle initially. Nothing happens, still.

Then, this iterator is wrapped in a `list()`, which will consume all of its arguments and build a list from it. To do so, it will start calling `next()` on the `islice()` instance, which in turn will start calling `next()` on our `f` instance.

On the first invocation, the code will finally run a bit: `prev, curr = 0, 1` gets executed, the `while True` loop is entered, and then it encounters the `yield curr` statement. It will produce the value that's currently in the `curr` variable and become idle again.

This value is passed to the `islice()` wrapper, which will produce it (because it's not past the 10th value yet), and list can add the value `1` to the list now.

Then, it asks `islice()` for the next value, which will ask f for the next value, which will "unpause" `f` from its previous state, resuming with the statement `prev, curr = curr, prev + curr`. Then it re-enters the next iteration of the while loop, and hits the `yield curr` statement, returning the next value of `curr`.

This happens until the output list is 10 elements long and when `list()` asks `islice()` for the 11th value, `islice()` will raise a `StopIteration` exception, indicating that the end has been reached, and list will return the result: a list of 10 items, containing the first 10 Fibonacci numbers. Notice that the generator doesn't receive the 11th `next()` call. In fact, it will not be used again, and will be garbage collected later.

Generators are particularly useful when dealing with large datasets or when you need to generate an infinite sequence of values, as they consume much less memory compared to creating an entire list of values.

You can also use generator expressions, which are similar to list comprehensions but return a generator object instead of a list. For example:

```python
# Generator expression
gen = (x ** 2 for x in range(5))
print(list(gen))  # Output: [0, 1, 4, 9, 16]
```

In this example, the generator expression `(x ** 2 for x in range(5))` generates squares of numbers from 0 to 4, and `list(gen)` converts the generator object to a list.

Generators are powerful tools in Python for working with large datasets or when you need to generate sequences of values efficiently. They follow the iterator protocol, making them compatible with constructs like for loops and comprehensions.

## Differences between List Comprehension and Generators

1. **Memory Usage:**
   - **List Comprehensions:** List comprehensions construct the entire list in memory before returning it. This means that if you have a large dataset, all elements will be stored in memory at once, potentially leading to high memory usage.
   - **Generators:** Generators produce values lazily, on-demand. They generate values one at a time and only when needed. This results in much lower memory consumption, especially for large datasets or when working with infinite sequences.

2. **Execution Time:**
   - **List Comprehensions:** List comprehensions are typically faster in terms of execution time compared to generators when you need to iterate over the entire sequence multiple times. This is because list comprehensions pre-compute the entire sequence and store it in memory, allowing for quick access to any element.
   - **Generators:** Generators are slower in terms of execution time when you need to repeatedly access elements in a sequence, especially if the generator involves complex computations. This is because generators generate each value on-the-fly, which incurs some overhead for each iteration.

3. **Use Cases:**
   - **List Comprehensions:** List comprehensions are suitable when you need to construct a list and then manipulate its elements multiple times, or when you need random access to elements in the sequence.
   - **Generators:** Generators are ideal for situations where memory efficiency is critical, such as when dealing with large datasets or when you need to generate an infinite sequence of values. They are also useful for one-time iteration tasks where you don't need to store the entire sequence in memory.
